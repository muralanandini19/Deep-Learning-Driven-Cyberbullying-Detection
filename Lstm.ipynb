{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ngz1pummEsp1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"cyberbullying_tweets.csv\")\n",
        "texts = data[\"tweet_text\"].tolist()\n",
        "labels = data[\"cyberbullying_type\"].tolist()"
      ],
      "metadata": {
        "id": "zt4cHNR3HYRD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)"
      ],
      "metadata": {
        "id": "CnYqx7JvHxym"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "k-dmQDIWIFqq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Dv5TDt_yIKfT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fPfqqTSIPLr",
        "outputId": "36cf4864-3795-48bf-c523-d7f0baec678b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TrDvNTGoIUch"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxbVr5dIZ05",
        "outputId": "62faf7e6-afdd-45fd-9ae2-297a6b785367"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 111ms/step - accuracy: 0.5992 - loss: 0.9513 - val_accuracy: 0.8091 - val_loss: 0.4702\n",
            "Epoch 2/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 108ms/step - accuracy: 0.8434 - loss: 0.3929 - val_accuracy: 0.8213 - val_loss: 0.4558\n",
            "Epoch 3/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 109ms/step - accuracy: 0.9030 - loss: 0.2806 - val_accuracy: 0.8207 - val_loss: 0.5138\n",
            "Epoch 4/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 108ms/step - accuracy: 0.9322 - loss: 0.1970 - val_accuracy: 0.8225 - val_loss: 0.5714\n",
            "Epoch 5/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 109ms/step - accuracy: 0.9447 - loss: 0.1561 - val_accuracy: 0.8105 - val_loss: 0.7191\n",
            "Epoch 6/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 108ms/step - accuracy: 0.9516 - loss: 0.1229 - val_accuracy: 0.8116 - val_loss: 0.7940\n",
            "Epoch 7/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 110ms/step - accuracy: 0.9568 - loss: 0.1054 - val_accuracy: 0.8096 - val_loss: 0.8845\n",
            "Epoch 8/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 109ms/step - accuracy: 0.9586 - loss: 0.0882 - val_accuracy: 0.8090 - val_loss: 0.9308\n",
            "Epoch 9/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 108ms/step - accuracy: 0.9620 - loss: 0.0797 - val_accuracy: 0.8066 - val_loss: 1.1182\n",
            "Epoch 10/10\n",
            "\u001b[1m1193/1193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 108ms/step - accuracy: 0.9623 - loss: 0.0775 - val_accuracy: 0.8094 - val_loss: 1.1186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = data[\"cyberbullying_type\"].unique().tolist()\n",
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs0UBTa4Ie8w",
        "outputId": "3ee5a8a0-fa1e-4844-cb04-96c3ec60da5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not_cyberbullying',\n",
              " 'gender',\n",
              " 'religion',\n",
              " 'other_cyberbullying',\n",
              " 'age',\n",
              " 'ethnicity']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB44s6KkOQ73",
        "outputId": "c66d0682-0468-474b-a38e-f266242398af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  329,   62,   44],\n",
              "       [   0,    0,    0, ..., 4183,   79,  784],\n",
              "       [   0,    0,    0, ...,  283,   23,  160],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 1588,   13,  577],\n",
              "       [   0,    0,    0, ...,    4,  230,  235],\n",
              "       [   0,    0,    0, ...,   85,  114,  422]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn7O9U_NN6Wj",
        "outputId": "8ce3d438-8145-4b07-d785-17d41472c7cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                age       0.96      0.97      0.96      1603\n",
            "          ethnicity       0.97      0.97      0.97      1603\n",
            "             gender       0.86      0.84      0.85      1531\n",
            "  not_cyberbullying       0.55      0.51      0.53      1624\n",
            "other_cyberbullying       0.58      0.65      0.61      1612\n",
            "           religion       0.95      0.92      0.93      1566\n",
            "\n",
            "           accuracy                           0.81      9539\n",
            "          macro avg       0.81      0.81      0.81      9539\n",
            "       weighted avg       0.81      0.81      0.81      9539\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(model, 'model_lstm.pth')"
      ],
      "metadata": {
        "id": "VEKJS80JN-Kd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/My Drive/model_lstm.pth')"
      ],
      "metadata": {
        "id": "-oUqV92aPt88"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "mp = torch.load('/content/drive/My Drive/model_cnn.pth', map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtdCyHb_P7rA",
        "outputId": "5713cec6-91f0-4d9c-896b-3d53bcfbb710"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-98492bc22dd2>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  mp = torch.load('/content/drive/My Drive/model_cnn.pth', map_location=torch.device('cpu'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_length)\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    return label_encoder.classes_[predicted_class]\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"you are a phsyco\"\n",
        "predicted_label = predict_text(sample_text)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E14l8X4gQH4s",
        "outputId": "7a38dcde-9501-4e4e-f375-3da80e911968"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "Predicted Label: other_cyberbullying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzBTyqL3QoBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}